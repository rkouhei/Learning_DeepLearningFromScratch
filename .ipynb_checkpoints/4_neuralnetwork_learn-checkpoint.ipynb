{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 損失関数\n",
    "import numpy as np\n",
    "\n",
    "# 2乗和誤差\n",
    "def mean_squared_error(y, t) :\n",
    "    return 0.5 * np.sum((y-t)**2)\n",
    "\n",
    "# 交差エントロピー誤差\n",
    "def cross_entropy_error(y, t) :\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0975\n",
      "0.510825457099\n"
     ]
    }
   ],
   "source": [
    "t = [0,0,1,0,0,0,0,0,0,0]\n",
    "y = [0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0]\n",
    "\n",
    "print(mean_squared_error(np.array(y),np.array(t)))\n",
    "print(cross_entropy_error(np.array(y),np.array(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "# ランダムに訓練データを取り出す\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# バッチデータに対応した交差エントロピー誤差\n",
    "def cross_entropy_error2(y,t) :\n",
    "    if y.ndim == 1 :\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y + 1e-7)) / batch_size\n",
    "\n",
    "# 教師データがone-hot表現でないとき\n",
    "def cross_entropy_error3(y,t) :\n",
    "    if y.ndim == 1 :\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))  /  batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 関数の微分を求める(中心差分)\n",
    "def numerical_diff(f,x) :\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119a45780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数値微分の例\n",
    "\n",
    "def function_1(x) :\n",
    "    return 0.01*x**2 + 0.1*x\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 偏微分\n",
    "def function_2(x) :\n",
    "    return x[0]**2 + x[1]**2\n",
    "\n",
    "# 勾配\n",
    "def numerical_gradient(f, x) :\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    for idx in range(x.size) :\n",
    "        tmp_val = x[idx]\n",
    "        # f(x+h)の計算\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h)の計算\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "        \n",
    "        grad = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勾配降下法\n",
    "def gradient_descent(f, init_x, lr=0.01, step_num=100) : # lrは学習率, step_numは最大学習回数\n",
    "    x = init_x\n",
    "    \n",
    "    for i in range(step_num) :\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークにおいて重みパラメータの勾配を求める\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet :\n",
    "    def __init__(self) :\n",
    "        self.W = np.random.randn(2,3)\n",
    "        \n",
    "    def predict(self, x) :\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t) :\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.03722884 -1.61613695 -0.5428469 ]\n",
      " [ 0.39562743 -1.47022018 -1.86606271]]\n",
      "[ 0.97840199 -2.29288033 -2.00516458]\n"
     ]
    }
   ],
   "source": [
    "# simpleNetを使ってみる\n",
    "net = simpleNet()\n",
    "print(net.W)\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.084864544504439879"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simpleNetを使ってみる\n",
    "t = np.array([1,0,0])\n",
    "net.loss(x,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2層ニューラルネットワーク\n",
    "\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet :\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01) :\n",
    "        # 重みの初期化\n",
    "        self.parms = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "        \n",
    "    def predict(self, x) :\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        \n",
    "        a1 = np.dot(x,W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1,W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # xは入力データ, tは教師データ\n",
    "    def loss(self, x, t) :\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y,t)\n",
    "    \n",
    "    def accuracy(self, x, t) :\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y==t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t) :\n",
    "        loss_W = lambda W: self.loss(x,t)\n",
    "        \n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ミニバッチ学習\n",
    "from dataset.mnist import load_mnist\n",
    "from ch04.two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "# ハイパーパラメータ\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num) :\n",
    "    # ミニバッチの取得\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 勾配の計算\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    #grad = network.gradient(x_batch, t_batch) # 高速版\n",
    "    \n",
    "    # パラメータの更新\n",
    "    for key in ('W1', 'b1', 'W2', 'b2') :\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "    # 学習経過の記録\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
